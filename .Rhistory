#### Combine Plot Ratios ----
final_by_crop<-rbind(final_Illinois_by_crop,final_Michigan_by_crop,final_Wisconsin_by_crop)
final_by_crop<-final_by_crop%>%group_by(Label)%>%mutate(NASSacresm = mean(NASSacres))
final_by_crop <- transform(final_by_crop, Label=reorder(Label, -(NASSacresm)) )
ratio_plotf<-ggplot(final_by_crop, aes(x=as.factor(Commodity), y=(log2(ratio)), fill=Commodity)) +
geom_boxplot()+
facet_wrap(.~Label, scales = "free")+
xlab("Crop") +
ylab("Acreage Ratio")+
labs(title = "Ratio NASS Acres to Field Acres, By Crop")+
theme(panel.background = element_blank(),
axis.line = element_line(colour = "black"),
axis.title.x=element_text(margin = margin(t = 10, r = 0, b = , l = 0), size=14,face="bold"),
axis.title.y=element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size=14,face="bold"),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
theme(legend.position = "none")
ratio_plotf
compare_boxf
compare_boxf<-compare_box +
geom_point(nass_data, mapping=aes(x=as.factor(County), y=log10(avg),group=1),size=3,color="black", shape=17)+
geom_point(nass_data, mapping=aes(x=as.factor(County), y=log10(avgcdl),group=1),size=3,color="darkgrey", shape=19)+
scale_y_continuous(limit = c(2.75, 6))+
theme_minimal()+
guides(fill=guide_legend(title="New Legend Title"))
compare_boxf
compare_box<-ggplot(nass_data, aes(x = as.factor(County), y = log10(sum_field), color=State))+
geom_boxplot()+
xlab("County") +
ylab("Log10(Sum Acreages)")+
labs(title = paste0("Comparison of Sum Total Crop Acreages in High vs. Low Agriculture Counties"))+
scale_y_continuous(n.breaks=8, expand = expansion(mult = c(0.1, 0.2)))+
theme(legend.position = "none",axis.title.y = element_text(margin = margin(t = 0, r = 15, b = 0, l = 0)),
axis.title.x = element_text(margin = margin(t = 5, r = 0, b = 0, l = 0)))
compare_box
compare_boxf<-compare_box +
geom_point(nass_data, mapping=aes(x=as.factor(County), y=log10(avg),group=1),size=3,color="black", shape=17)+
geom_point(nass_data, mapping=aes(x=as.factor(County), y=log10(avgcdl),group=1),size=3,color="darkgrey", shape=19)+
scale_y_continuous(limit = c(2.75, 6))+
theme_minimal()
compare_boxf
View(final_I)
View(layer_by_year_crops)
n=1
#county_name<-'CHAMPAIGN'
county<-acreages_by_countyI[[n]]
county_name<-names(acreages_by_countyI[n])
names(county)<-years
list_of_year<-list()
for(y in 1:length(county)){
year_list<-county[[y]]
list_of_field<-list()
for(layer in 1:length(year_list)){
layer_by_year<-year_list[[layer]]
layer_by_year$year<-as.numeric(names(county[y]))
layer_by_year$Category<-  toupper(layer_by_year$Category)
#layer_by_year<-layer_by_year[!layer_by_year$Category == "OTHER HAY/NON ALFALFA",] #add in winter wheat?? no
layer_by_year<-year_list[[layer]]
layer_by_year$year<-as.numeric(names(county[y]))
layer_by_year$Category<-  toupper(layer_by_year$Category)
layer_by_year$Category[grepl('WINTER', layer_by_year$Category)] <- 'WHEAT'
layer_by_year$Category[grepl('OTHER HAY/NON ALFALFA', layer_by_year$Category)] <- 'HAY'
layer_by_year$Category[grepl('ALFALFA', layer_by_year$Category)] <- 'HAY'
layer_by_year$x<-ifelse(layer_by_year$Class ==  36, with(layer_by_year,sum(x[Category =='HAY'])), layer_by_year$x)
layer_by_year<-layer_by_year[!layer_by_year$Class == 37,] #drop the other hay class because we merged it with the alfalfa class
layer_by_year$threshold<-15-layer
list_of_field[[layer]]<-layer_by_year
}
list_of_year[[y]]<-do.call(rbind, list_of_field)
}
field_data<-do.call(rbind, list_of_year)
View(field_data)
#NASS data
ill_nassx<-ill_nass[!ill_nass$Value == " (D)",]
ill_nassx$Value<-as.numeric(as.numeric(gsub(",", "", ill_nassx$Value)))
ill_nass_y<- ill_nassx %>%
#filter(Year %in% c(layer_by_year$year)) %>%
filter(County %in% county_name) %>%
filter_at(vars(starts_with("Data.Item")), all_vars(grepl('HARVESTED|BEARING & NON-BEARING', .)))%>% #use 'non' to filter bearing and non-bearing
filter_at(vars(starts_with("Data.Item")), all_vars(!grepl('OPERATIONS|SMALL|PROCESSING', .)))%>%
group_by(Commodity, Year) %>% summarise(sum = sum(as.numeric(Value)))
names(field_data)[3]<-"Commodity"
names(field_data)[2]<-"fieldacres"
layer_by_year_crops<-left_join(field_data, ill_nass_y, by = c("Year","Commodity"))
colnames(layer_by_year_crops)[8]<-"NASSacres"
View(layer_by_year_crops)
layer_by_year_crops[is.na(layer_by_year_crops)] <- 0
acreages_by_countyI<-readRDS(paste0(root_data_out,"/acreages_by_countyI.RData"))
cntynames<-c('CHAMPAIGN',"DU PAGE","MCHENRY")
names(acreages_by_countyI)<-cntynames
list_of_final_data_by_countyI<-list()
for(n in 1:length(acreages_by_countyI)){
#county_name<-'CHAMPAIGN'
county<-acreages_by_countyI[[n]]
county_name<-names(acreages_by_countyI[n])
names(county)<-years
list_of_year<-list()
for(y in 1:length(county)){
year_list<-county[[y]]
list_of_field<-list()
for(layer in 1:length(year_list)){
layer_by_year<-year_list[[layer]]
layer_by_year$year<-as.numeric(names(county[y]))
layer_by_year$Category<-  toupper(layer_by_year$Category)
#layer_by_year<-layer_by_year[!layer_by_year$Category == "OTHER HAY/NON ALFALFA",] #add in winter wheat?? no
layer_by_year<-year_list[[layer]]
layer_by_year$year<-as.numeric(names(county[y]))
layer_by_year$Category<-  toupper(layer_by_year$Category)
layer_by_year$Category[grepl('WINTER', layer_by_year$Category)] <- 'WHEAT'
layer_by_year$Category[grepl('OTHER HAY/NON ALFALFA', layer_by_year$Category)] <- 'HAY'
layer_by_year$Category[grepl('ALFALFA', layer_by_year$Category)] <- 'HAY'
layer_by_year$x<-ifelse(layer_by_year$Class ==  36, with(layer_by_year,sum(x[Category =='HAY'])), layer_by_year$x)
layer_by_year<-layer_by_year[!layer_by_year$Class == 37,] #drop the other hay class because we merged it with the alfalfa class
layer_by_year$threshold<-15-layer
list_of_field[[layer]]<-layer_by_year
}
list_of_year[[y]]<-do.call(rbind, list_of_field)
}
field_data<-do.call(rbind, list_of_year)
#NASS data
ill_nassx<-ill_nass[!ill_nass$Value == " (D)",]
ill_nassx$Value<-as.numeric(as.numeric(gsub(",", "", ill_nassx$Value)))
ill_nass_y<- ill_nassx %>%
#filter(Year %in% c(layer_by_year$year)) %>%
filter(County %in% county_name) %>%
filter_at(vars(starts_with("Data.Item")), all_vars(grepl('HARVESTED|BEARING & NON-BEARING', .)))%>% #use 'non' to filter bearing and non-bearing
filter_at(vars(starts_with("Data.Item")), all_vars(!grepl('OPERATIONS|SMALL|PROCESSING', .)))%>%
group_by(Commodity, Year) %>% summarise(sum = sum(as.numeric(Value)))
#|SILAGE|IRRIGATED
names(field_data)[3]<-"Commodity"
names(field_data)[2]<-"fieldacres"
layer_by_year_crops<-left_join(field_data, ill_nass_y, by = c("Year","Commodity"))
colnames(layer_by_year_crops)[8]<-"NASSacres"
layer_by_year_crops[is.na(layer_by_year_crops)] <- 0
#layer_by_year_crops<-na.omit(layer_by_year_crops) #IF there are no crops represented in NASS for that year, drop those rows
layer_by_year_crops$County<-cntynames[[n]]
list_of_final_data_by_countyI[[n]]<-layer_by_year_crops
}
cntynames<-c('CHAMPAIGN',"DU PAGE","MCHENRY")
list_of_plotsI<-list()
list_of_dataI<-list()
for(c in 1:length(list_of_final_data_by_countyI)){
layer_by_year_crops<-list_of_final_data_by_countyI[[c]]
extracted_cdl_dataI$CDLacres<-((extracted_cdl_dataI$count)*900)*0.000247105
colnames(extracted_cdl_dataI)[1]<-'Class'
layer_by_year_crops<-left_join(layer_by_year_crops, extracted_cdl_dataI, by=c("County","year","Class"))
#Plot showing combined data
sum_field<-layer_by_year_crops %>% group_by(year, threshold) %>% summarise(sumf = sum(as.numeric(fieldacres)))
sum_nass<-layer_by_year_crops %>% group_by(year, threshold) %>% summarise(sumf = sum(as.numeric(NASSacres)))
sum_cdl<-layer_by_year_crops %>% group_by(year, threshold) %>% summarise(sumf = sum(as.numeric(CDLacres)))
all_data<-cbind(sum_field,sum_nass, sum_cdl)
names(all_data)<-c("year","thresh","sum_field","year","thresh","sum_nass","year","thresh","sum_cdl")
all_data<-all_data[,c(1:3,6,9)]
#because some thresholds include crops that others don't, we need to modify the final NASS values to reflect that
all_data_t <- all_data %>% group_by(year) %>%
mutate(sum_nass = ifelse(max(sum_nass) > min(sum_nass),  max(sum_nass), min(sum_nass)))
all_data_t <- all_data_t %>% group_by(year) %>%
mutate(sum_cdl = ifelse(max(sum_cdl) > min(sum_cdl),  max(sum_cdl), min(sum_cdl)))
all_data_t$County<-names(field_list_ill_f)[c]
list_of_dataI[[c]]<-all_data_t
#plot showing the specific changes in acreage by year specific to each County
ratio_plot<-ggplot(all_data_t, aes(x=year, y=(sum_field), fill=factor(thresh), colour=factor(thresh))) +
geom_point()+
geom_line()+
xlab("Year") +
ylab("Acreages")+
scale_x_discrete(name ="Year",
limits=c(2008:2021))+
scale_y_continuous(n.breaks=8, expand = expansion(mult = c(0, .1)))+
labs(title = paste0(names(field_list_ill_f)[c]," County Total Field Acres to NASS Acres, by Threshold"))+
guides(fill=guide_legend(title="Threshold"), colour=guide_legend(title="Threshold"))+
theme(panel.background = element_blank(),
axis.line = element_line(colour = "black"),
axis.title.x=element_text(margin = margin(t = 10, r = 0, b = , l = 0), size=14,face="bold"),
axis.title.y=element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size=14,face="bold"),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
ratio_plot
output<-ratio_plot+
geom_point(all_data_t,mapping=aes(y=(sum_nass)), col='black') +
geom_line(all_data_t,mapping=aes(y=(sum_nass)), col='black')+
geom_point(all_data_t,mapping=aes(y=(sum_cdl)), col='darkgrey') +
geom_line(all_data_t,mapping=aes(y=(sum_cdl)), col='darkgrey')
output
list_of_plotsI[[c]]<-output
}
final_Illinois<-do.call(rbind, list_of_dataI)
final_Illinois <- final_Illinois %>% group_by(thresh, County) %>% mutate(avgfield =mean(sum_field))
###Here is where we put everything together...
final_I<-final_Illinois[final_Illinois$thresh==1,]
#remove weird outlier from Ill
final_I<-final_I[!c(final_I$year == 2021 & final_I$County == "McHenry"),]
ratio_plot<-ggplot(final_I, aes(x=year, y=log(sum_field), group=County, fill=factor(County), colour=factor(County))) +
geom_point()+
geom_line()+
xlab("Year") +
ylab("Log(Sum Acreages)")+
scale_x_discrete(name ="Year",
limits=c(2008:2021))+
scale_y_continuous(n.breaks=8, expand = expansion(mult = c(0, .1)))+
labs(title = paste0("Illinois County Total Field Acres to NASS Acres"))+
guides(fill=guide_legend(title="County"), colour=guide_legend(title="County"))+
theme(panel.background = element_blank(),
axis.line = element_line(colour = "black"),
axis.title.x=element_text(margin = margin(t = 10, r = 0, b = , l = 0), size=14,face="bold"),
axis.title.y=element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size=14,face="bold"),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
ratio_plot
Ioutput<-ratio_plot+
geom_point(final_I,mapping=aes(y=log(sum_nass),group=County, shape=County),col='black') +
geom_line(final_I,mapping=aes(y=log(sum_nass),group=County), col='black')+
geom_point(final_I,mapping=aes(y=log(sum_cdl),group=County, shape=County),col='darkgrey') +
geom_line(final_I,mapping=aes(y=log(sum_cdl),group=County),col='darkgrey')
Ioutput
View(low_box)
View(final_I)
final_I$sum_nass<-ifelse(final_I$sum_nass == 0,NA,final_I$sum_nass)
View(final_I)
final_I<-na.omit(final_I)
Ioutput<-ratio_plot+
geom_point(final_I,mapping=aes(y=log(sum_nass),group=County, shape=County),col='black') +
geom_line(final_I,mapping=aes(y=log(sum_nass),group=County), col='black')+
geom_point(final_I,mapping=aes(y=log(sum_cdl),group=County, shape=County),col='darkgrey') +
geom_line(final_I,mapping=aes(y=log(sum_cdl),group=County),col='darkgrey')
Ioutput
library(Rcpp)
library(RcppGSL)
library(RcppEigen)
library(forcats)
library(plotly)
library(shiny)
library(scales)
library(ToxicR) ##
library(nlme)
library(ggplot2)
library(ggridges)
library(gridExtra)
library(grid)
library(readr)
library(bayestestR)
library(dplyr)
library(tidyverse)
library(cowplot)
library(drc)
set.seed(6379)
#script for comparing LD50 DDs as boxpltos across Web-ICE, SSD estimates, and our OG data 1000 sims
setwd('C:/Users/epauluko/OneDrive - Environmental Protection Agency (EPA)/Profile/Documents/GitHub/amphibian_effects_model')
#simulated datasets
sims<-read.csv('data_out/BMDS_glyphosate_fin_32122.csv') #read in the compiled simulation data from 'Data_Simulation.R'
by_s<-split(sims, list(sims$set), drop=T) #split by simulation
#Web-ICE raw data
ld50<-read.csv('data_in/ld50_glypho.csv')
gam_fit <- lapply(by_s, function(y) single_dichotomous_fit(y[,2],y[,4],y[,3],model_type="gamma",fit_type="laplace"))
nsims <- 1000
mortality_df <- as.data.frame(matrix(ncol = nsims, nrow = nd))
mortality_df_ld50<-as.data.frame(matrix(ncol = nsims, nrow = 1))
dose_df<-as.data.frame(matrix(ncol = nsims, nrow = nd))
dose_df_ld50<-as.data.frame(matrix(ncol = nsims, nrow = 1))
nd<-39
nsims <- 1000
mortality_df <- as.data.frame(matrix(ncol = nsims, nrow = nd))
mortality_df_ld50<-as.data.frame(matrix(ncol = nsims, nrow = 1))
dose_df<-as.data.frame(matrix(ncol = nsims, nrow = nd))
dose_df_ld50<-as.data.frame(matrix(ncol = nsims, nrow = 1))
dose_df_quant<-as.data.frame(matrix(ncol = nsims, nrow = 1))
for(i in 1:length(by_s)){
parms <- gam_fit[[i]]$parameters
g <-  1/(1+exp(-parms[1]));
a <- parms[2];
b <- parms[3];
d<-by_s[[i]]$Dose
mortality_df[,i] <- g + (1-g)*pgamma(b*d,a,1)
dose_df[,i]<-d
mortality_df_ld50[,i]<-which(abs(mortality_df[,i] - 0.50) == min(abs(mortality_df[,i]  - 0.50)))
dose_df_ld50[,i]<-dose_df[mortality_df_ld50[,i],]
dose_df_quant[,i]<-quantile(dose_df[,i],probs = c(0.50), names=T)
}
library(dplyr) # Used for data manipulation
library(tidyr) # data manipulation
library(data.table) # Used for creating data tables
library(EnvStats) # Used for calculating geometric means
library(fitdistrplus) # for fitting various distributions to the data
library(flexsurv) # for fitting parametric distributions
library(ggplot2) # for plotting
library(readxl) # read in excel sheets
# Read in the amphibian data
data <- readxl::read_xlsx("data_in/AqICE_PredAmphib_PyraGlypho (003).xlsx")
# Extract only relevant columns
data <- data[, c(1:4,7)]
# Rename columns
colnames(data) <- c("Chemical", "Surrogate", "Prediction", "LC50", "Units")
# Remove NAs
data <- na.omit(data)
# Filter into glyphosate dataset
glyphosate <- data %>%
filter(
Chemical == "Glyphosate"
)
# Set the chemical to Glyphosate, save as a variable
single.ssd.chem <- "Glyphosate"
# Create an empty list to hold the output value
individual.hc5s <- list()
#This loop calculates HC5 values from chemical-specific SSDs for each chemical in the all.chems list. It uses the best-fit method to fit the most appropriate distribution to individual chemical toxicity data (out of log-normal, log-logisitc, Weibull, and gamma distributions). The Anderson-Darling statistic is used to determine best-fit. The distribution with the lowest Anderson-Darling statistic is assigned as the "best.fit" method.
for(i in single.ssd.chem) {
fit_gamma <- NULL
best.fit <- NULL
#Calculating the average toxicity value (LC50) for each species
IndividualSSDs <- data %>% filter(Chemical == i) %>%
group_by(Prediction) %>%
summarise(
average = geoMean(LC50), # here I am using "average" instead of "geomean" as earlier
minimum = min(LC50),
sd = sd(LC50),
n = n())
IndividualSSDs <- unique(IndividualSSDs) #Adding toxicity data for each chemical to a list and making sure there are no duplicates
# Create intermediate data frame
Newdf <- IndividualSSDs
#Calculating the probability points for each species
df <- Newdf[order(Newdf$average),]
df$frac <- ppoints(df$average, 0.5)
df
#Fit a distribution to the plotted points
fit_llogis <- fitdist(df$average, "llogis") # fit llogis
fit_lnorm <- fitdist(df$average, "lnorm") # fit log normal
fit_gamma <- try(fitdist(df$average, "gamma"), silent = TRUE) # use try here as gamma often fails
fit_weibull <- fitdist(df$average, "weibull") # fit weibull
# if there is an error with the gamma distribution, fit the other three instead
if("try-error" %in% class(fit_gamma)){
ll <- gofstat(fit_llogis)
ln <- gofstat(fit_lnorm)
w <- gofstat(fit_weibull)
#Fit the best distribution to the data; identify it by the lowest anderson darling statistic
a <- unlist(c(ll[8], ln[8], w[8]))
best.fit.table <- data.table(c("llogis", "lnorm", "weibull"), a)
m <- min(a)
b <- best.fit.table$V1[best.fit.table$a == m]
}  else {
ll <- gofstat(fit_llogis)
ln <- gofstat(fit_lnorm)
g <- gofstat(fit_gamma)
w <- gofstat(fit_weibull)
#Fit the best distribution to the data; identify it by the lowest anderson darling statistic
a <- unlist(c(ll[8], ln[8], g[8], w[8]))
best.fit.table <- data.table(c("llogis", "lnorm", "gamma", "weibull"), a)
m <- min(a)
b <- best.fit.table$V1[best.fit.table$a == m]}
#Calculate the best fit distribution
best.fit <- fitdist(df$average, b)
# Extract the estimated HC5 value
hc5 <- quantile(best.fit, probs = 0.05)
Estimated_HC5 <- hc5$quantiles$`p=0.05`
# Bootstrap the HC5 value with upper and lower CIs
fit_boot <- bootdist(best.fit, bootmethod = 'param', niter = 1000)
# This step is not necessary I am just using it to check the bootstrap is working
bootstrap_hc5 <- quantile(fit_boot, probs = 0.05)
# Save the bootstrap and upper and lower confidence intervals
Bootstrapped_HC5 <- bootstrap_hc5$quantiles$`p=0.05`
HC5_lower_ci <- bootstrap_hc5$quantCI[1,1]
HC5_upper_ci <- bootstrap_hc5$quantCI[2,1]
# Save the HC5 values
hc5.table <- data.frame(i, Estimated_HC5, Bootstrapped_HC5, HC5_lower_ci, HC5_upper_ci, b, m)
individual.hc5s[[i]] <- hc5.table
}
#Binding the list of individual SSD hc5 values together
individual.hc5s <- rbindlist(individual.hc5s)
colnames(individual.hc5s) <- c("Chemical", "SSD Estimated HC5", "SSD Bootstrapped HC5", "HC5 Lower CI", "HC5 Upper CI", "SSD Dist.", "SSD AD")
# Save the glyphosate HC5 as its own dataframe
gly.pred.best.fit.hc5 <- individual.hc5s
# View the best fit table for Glyphosate
best.fit.table
# Check glyphosate hc5
gly.pred.best.fit.hc5
# Open an empty list to hold the output of the loop below
HC.list <- list()
# Create a sequence increasing be 0.05
initial.seq <- seq(0.05, 0.95, by = 0.05)
# Add 0.01 and 0.99 to the beginning and end, respectively
initial.seq <- append(initial.seq, 0.99) # add .99 to end
initial.seq <- append(initial.seq, 0.01, 0) # add 0.01 to front
# Check sequence
initial.seq
length(initial.seq)
# This sequence now has all the "HC" values ranging from HC1 to HC99 by 5. Length of 21
# Create a loop that iterates through the sequence, takes the value, applies it to the ith value of the distribution (ie 0.01 = the HC1)
for (i in 1:21){ # there are 21 values between 0.01 to 0.99
# Set an index to match the sequence
index <- initial.seq[i]
# Bootstrap upper and lower CIs around the value (1000 iterations)
fit_boot <- bootdist(best.fit, bootmethod = 'param', niter = 1000)
# Save the HC value
HC.bootstrap <- quantile(fit_boot, probs = index)
# Save HCs for that value
HC.value.1 <- HC.bootstrap[[1]]
HC.value.2 <- HC.value.1[1,1]
# Save upper and lower CIs for that value
HC.lower.CI <- HC.bootstrap$quantCI[1,1]
HC.upper.CI <- HC.bootstrap$quantCI[2,1]
# save all into table
final.table <- data.table(index, HC.value.2, HC.upper.CI, HC.lower.CI)
# Save the results of each run to a single element of the list
HC.list[[i]] <- final.table
}
# Bind all list elements together into a dataframe (so each element is a row now)
HC.list <- rbindlist(HC.list)
# Save as surrogate HC data. Add in distribution used, as well as what data this is coming from
Gly.Pred.HC.Data <- HC.list
# CHange column names
colnames(Gly.Pred.HC.Data) <- c("Percentile", "HC.Value", "HC.Upper.CI", "HC.Lower.CI")
# Add in distribution and data ID
Gly.Pred.HC.Data$Distribution <- "llogis"
Gly.Pred.HC.Data$Data.ID <- "Glyphosate.Prediction"
# Filter the data to only include surrogate species for glyphosate
gly_pred <- glyphosate %>%
group_by(Prediction) %>% # group by surrogate
summarise(
geomean = geoMean(LC50)
)
# Remove duplicate values as we have already calculated the geomean
gly_pred <- unique(gly_pred)
# Create an intermediate data frame to for calculations
gly_pred_df <- gly_pred
# Order the species by toxicity values and calculate the fraction
df <- gly_pred_df[order(gly_pred_df$geomean),]
# ppoints calculates a distribution of probability points
df$frac <- ppoints(df$geomean, 0.5)
# Re-order the points once again based on the distribution
df <- df[order(df$geomean), ]
# Plot the raw data
ggplot(data = df) + # the input data is the glyphosate data
geom_point(aes(x = geomean, y = frac), size = 3) + # the points are the geomeans
geom_text(aes(x = geomean, y = frac, label = Prediction), hjust = 1.1, size = 3) + # the text is the species label
theme_bw() +
scale_x_log10(limits = c(0.005, max(df$geomean))) + # set the x axis limits
labs(x = expression(paste('Concentration of Glyphosate [ mg ', L^-1, ' ]')),
y = 'Fraction of species affected') # add a label to the axes
# Use fitdistrplus to fit a distribution to the data
fit <- fitdist(df$geomean, "llogis") # fit a distribution to the geometric means of species
# The output gives the estimate of the mean log as well as standard errors
fit
# Predict the points from the distribution on a grid of 1000
## Generate x values
newxs <- 10^(seq(log10(0.0001), (log10(max(df$geomean))+2.5), length.out = 1000)) #creating a sequence from the smallest value to the largest value (with a bit extra so the plot does not just end at the largest value)
## Create the grid
pp <- apply(fit_boot$estim, 1, function(x) pllogis(newxs, x[1], x[2])) # using the "plnorm" function because we fit the log-normal distribution
## Make the grid a data frame
bootdat <- data.frame(pp) # each column is the result from a bootstrap sample
## add x-values
bootdat$newxs <- newxs
require(reshape2) # needed for data manipulation
## bring to long format
bootdat <- melt(bootdat, id.vars = 'newxs')
## get Ci from bootstraps
cis <- apply(pp, 1, quantile, c(0.025, 0.975))
## Label the lower and upper confidence intervals
rownames(cis) <- c('lwr' ,'upr')
## Save the x values and y values into a dataframe
pdat <- data.frame(newxs, py = pllogis(newxs, shape = fit$estimate[1], scale = fit$estimate[2]))
## add CI
pdat <- cbind(pdat, t(cis))
# add x coordinates for species names from fitted values
df$fit <- 10^(log10(qllogis(df$frac, shape = fit$estimate[1], scale = fit$estimate[2])) - 0.4)
#from the original DF: our LD50 was 0.017
toxicR<-as.data.frame(t(dose_df_ld50))
toxicR$Name<-"ToxicR"
names(toxicR)[1]<-"Dose"
#now let's get the original LD50s from web-ICE
names(ld50)<-c("Dose","Name")
ld50$Name<-"Web-ICE"
#to get Alex's data, you'll need to run the x_amphibian.rmd to get the full set of 1000 simulated lines and pull out the
#doses associated with the HC5
hc5dat<-bootdat %>%
group_by(variable) %>%
arrange(abs(value - 0.05)) %>%
slice(1)
#HC50 (50 percent of species impacted)
hc50dat<-bootdat %>%
group_by(variable) %>%
arrange(abs(value - 0.50)) %>%
slice(1)
hc50dat<-hc50dat[,1:2]
names(hc50dat)<-c("Dose","Name")
hc50dat$Name<-"SSD"
hc50dat$Dose<-hc50dat$Dose* (0.05*(10^-3.4)) # convet to LC50* BCF
ld50_df<-rbind(toxicR,ld50, hc50dat)
ggplot(data=ld50_df,aes(x=Name, y=log(Dose),group=Name, fill=Name))+
geom_boxplot()
#use HC5s
hc5dat<-hc5dat[,1:2]
names(hc5dat)<-c("Dose","Name")
hc5dat$Name<-"SSD"
hc5dat$Dose<-hc5dat$Dose* (0.05*(10^-3.4)) # convet to LC50* BCF
ld50_df<-rbind(toxicR,ld50, hc5dat)
ld50_df$Name<-factor(ld50_df$Name, levels = c("SSD","Web-ICE","ToxicR"))
ggplot(data=ld50_df,aes(x=Name, y=log(Dose),group=Name, fill=Name))+
geom_boxplot()
#OG prediction SSD (using Alex's model estimate)
ld50_alex<-as.data.frame(Gly.Pred.HC.Data$HC.Value)
names(ld50_alex)<-"Dose"
ld50_alex$Name<-"SSD"
ld50_alex$Dose<-ld50_alex$Dose* (0.05*(10^-3.4)) # convet to LC50* BCF
ld50_df<-rbind(toxicR,ld50, ld50_alex)
ld50_df$Name<-factor(ld50_df$Name, levels = c("SSD","Web-ICE","ToxicR"))
ggplot(data=ld50_df,aes(x=Name, y=(Dose),group=Name, fill=Name))+
geom_boxplot()+
labs(y = expression(paste('Log Glyphosate LD50 [ ug ', g^-1, ' ]')),
x = 'Method',
title = paste0("Comparison of LD50 estimates across 3 Methods")) +
theme_minimal()
ggplot(data=ld50_df,aes(x=Name, y=log(Dose),group=Name, fill=Name))+
geom_boxplot()+
labs(y = expression(paste('Log Glyphosate LD50 [ ug ', g^-1, ' ]')),
x = 'Method',
title = paste0("Comparison of LD50 estimates across 3 Methods")) +
theme_minimal()
